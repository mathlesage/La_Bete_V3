"""
Script d'analyse d√©taill√©e des hard negatives par prompt
Teste sur 100 √©chantillons et analyse les performances de chaque prompt
"""

import json
import numpy as np
from typing import List, Dict
from collections import defaultdict
import pandas as pd
from datasets import load_dataset

def load_mathlesage_dataset(n_samples=100):
    """Charge le dataset Mathlesage depuis HuggingFace"""
    print("Chargement du dataset Mathlesage/La_Bete_data_2...")
    
    try:
        # Charger le dataset depuis HuggingFace
        dataset = load_dataset("Mathlesage/La_Bete_data_2", split="train")
        
        # Pr√©parer les donn√©es pour le g√©n√©rateur
        samples = []
        for i in range(min(n_samples, len(dataset))):
            sample = {
                "query": dataset[i]["anchor"],
                "positive": dataset[i]["response"]
            }
            samples.append(sample)
        
        print(f"‚úì {len(samples)} √©chantillons charg√©s")
        return samples
    
    except Exception as e:
        print(f"Erreur lors du chargement: {e}")
        print("Utilisation d'√©chantillons de test...")
        # Fallback sur des √©chantillons de test
        return [
            {
                "query": "Comment installer Python ?",
                "positive": "T√©l√©chargez Python depuis python.org et lancez l'installateur."
            },
            {
                "query": "Qu'est-ce que React ?",
                "positive": "React est une biblioth√®que JavaScript pour cr√©er des interfaces."
            }
        ]

def analyze_by_prompt(results: List[Dict]) -> Dict:
    """
    Analyse les r√©sultats par prompt
    
    Returns:
        Dict avec statistiques par prompt
    """
    # Organiser par prompt
    by_prompt_query = defaultdict(list)
    by_prompt_positive = defaultdict(list)
    
    for result in results:
        prompt_q = result.get('prompt', 'unknown')
        prompt_p = result.get('prompt_used_positive', 'unknown')
        
        by_prompt_query[prompt_q].append(result['sim_query_hardneg_q'])
        by_prompt_positive[prompt_p].append(result['sim_query_hardneg_p'])
    
    # Analyser chaque prompt
    analysis = {
        'query_based': {},
        'positive_based': {}
    }
    
    # Analyse des prompts query-based
    for prompt, sims in by_prompt_query.items():
        if sims:
            sims_array = np.array(sims)
            analysis['query_based'][prompt] = {
                'count': len(sims),
                'mean': float(np.mean(sims_array)),
                'std': float(np.std(sims_array)),
                'min': float(np.min(sims_array)),
                'max': float(np.max(sims_array)),
                'below_0.3': int(np.sum(sims_array < 0.3)),
                'in_range_0.3_0.6': int(np.sum((sims_array >= 0.3) & (sims_array <= 0.6))),
                'above_0.6': int(np.sum(sims_array > 0.6)),
                'percent_in_range': float(np.sum((sims_array >= 0.3) & (sims_array <= 0.6)) / len(sims) * 100)
            }
    
    # Analyse des prompts positive-based
    for prompt, sims in by_prompt_positive.items():
        if sims:
            sims_array = np.array(sims)
            analysis['positive_based'][prompt] = {
                'count': len(sims),
                'mean': float(np.mean(sims_array)),
                'std': float(np.std(sims_array)),
                'min': float(np.min(sims_array)),
                'max': float(np.max(sims_array)),
                'below_0.3': int(np.sum(sims_array < 0.3)),
                'in_range_0.3_0.6': int(np.sum((sims_array >= 0.3) & (sims_array <= 0.6))),
                'above_0.6': int(np.sum(sims_array > 0.6)),
                'percent_in_range': float(np.sum((sims_array >= 0.3) & (sims_array <= 0.6)) / len(sims) * 100)
            }
    
    return analysis

def print_detailed_analysis(analysis: Dict):
    """Affiche l'analyse d√©taill√©e par prompt"""
    
    print("\n" + "="*80)
    print("ANALYSE D√âTAILL√âE PAR PROMPT")
    print("="*80)
    
    # Analyse des prompts query-based
    print("\nüìä PROMPTS QUERY-BASED")
    print("-"*40)
    
    for prompt, stats in sorted(analysis['query_based'].items(), 
                                key=lambda x: x[1]['percent_in_range'], reverse=True):
        print(f"\n‚ú¶ {prompt} ({stats['count']} utilisations)")
        print(f"  Moyenne: {stats['mean']:.3f} (¬±{stats['std']:.3f})")
        print(f"  Range: [{stats['min']:.3f}, {stats['max']:.3f}]")
        print(f"  Distribution:")
        print(f"    ‚Ä¢ < 0.3: {stats['below_0.3']} ({stats['below_0.3']/stats['count']*100:.1f}%)")
        print(f"    ‚Ä¢ 0.3-0.6: {stats['in_range_0.3_0.6']} ({stats['percent_in_range']:.1f}%) ‚úì")
        print(f"    ‚Ä¢ > 0.6: {stats['above_0.6']} ({stats['above_0.6']/stats['count']*100:.1f}%)")
        
        # √âvaluation
        if stats['percent_in_range'] >= 70:
            print(f"  üü¢ Excellent - {stats['percent_in_range']:.0f}% dans la cible")
        elif stats['percent_in_range'] >= 50:
            print(f"  üü° Bon - {stats['percent_in_range']:.0f}% dans la cible")
        else:
            print(f"  üî¥ √Ä am√©liorer - seulement {stats['percent_in_range']:.0f}% dans la cible")
    
    # Analyse des prompts positive-based
    print("\n\nüìä PROMPTS POSITIVE-BASED")
    print("-"*40)
    
    for prompt, stats in sorted(analysis['positive_based'].items(), 
                                key=lambda x: x[1]['percent_in_range'], reverse=True):
        print(f"\n‚ú¶ {prompt} ({stats['count']} utilisations)")
        print(f"  Moyenne: {stats['mean']:.3f} (¬±{stats['std']:.3f})")
        print(f"  Range: [{stats['min']:.3f}, {stats['max']:.3f}]")
        print(f"  Distribution:")
        print(f"    ‚Ä¢ < 0.3: {stats['below_0.3']} ({stats['below_0.3']/stats['count']*100:.1f}%)")
        print(f"    ‚Ä¢ 0.3-0.6: {stats['in_range_0.3_0.6']} ({stats['percent_in_range']:.1f}%) ‚úì")
        print(f"    ‚Ä¢ > 0.6: {stats['above_0.6']} ({stats['above_0.6']/stats['count']*100:.1f}%)")
        
        # √âvaluation
        if stats['percent_in_range'] >= 70:
            print(f"  üü¢ Excellent - {stats['percent_in_range']:.0f}% dans la cible")
        elif stats['percent_in_range'] >= 50:
            print(f"  üü° Bon - {stats['percent_in_range']:.0f}% dans la cible")
        else:
            print(f"  üî¥ √Ä am√©liorer - seulement {stats['percent_in_range']:.0f}% dans la cible")

def calculate_global_stats(results: List[Dict]) -> Dict:
    """Calcule les statistiques globales"""
    
    all_query_sims = [r['sim_query_hardneg_q'] for r in results]
    all_positive_sims = [r['sim_query_hardneg_p'] for r in results]
    all_sims = all_query_sims + all_positive_sims
    
    return {
        'total_samples': len(results),
        'total_hard_negatives': len(all_sims),
        'global_mean': float(np.mean(all_sims)),
        'global_std': float(np.std(all_sims)),
        'global_below_0.3': int(np.sum(np.array(all_sims) < 0.3)),
        'global_in_range': int(np.sum((np.array(all_sims) >= 0.3) & (np.array(all_sims) <= 0.6))),
        'global_above_0.6': int(np.sum(np.array(all_sims) > 0.6)),
        'global_percent_in_range': float(np.sum((np.array(all_sims) >= 0.3) & (np.array(all_sims) <= 0.6)) / len(all_sims) * 100)
    }

def save_analysis_report(analysis: Dict, global_stats: Dict, output_file: str = "analysis_report.json"):
    """Sauvegarde le rapport d'analyse"""
    report = {
        "timestamp": pd.Timestamp.now().isoformat(),
        "global_statistics": global_stats,
        "prompt_analysis": analysis
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìÅ Rapport d√©taill√© sauvegard√© dans: {output_file}")

def main():
    """Fonction principale"""
    
    print("üöÄ Analyse des Hard Negatives sur 100 √©chantillons")
    print("="*60)
    
    # 1. Charger le dataset
    dataset = load_mathlesage_dataset(n_samples=100)
    
    # 2. Sauvegarder pour le g√©n√©rateur
    with open('dataset_100.json', 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    print("üìÅ Dataset sauvegard√© dans: dataset_100.json")
    
    # 3. V√©rifier si les r√©sultats existent d√©j√†
    try:
        with open('test_results.json', 'r', encoding='utf-8') as f:
            results = json.load(f)
        print(f"‚úì R√©sultats charg√©s: {len(results)} √©chantillons")
    except FileNotFoundError:
        print("\n‚ö†Ô∏è Pas de r√©sultats trouv√©s.")
        print("Veuillez d'abord:")
        print("1. G√©n√©rer les hard negatives: python hard_negatives_generator.py")
        print("2. Tester les embeddings: python test_hard_negatives.py")
        return
    
    # 4. Analyser par prompt
    analysis = analyze_by_prompt(results)
    
    # 5. Calculer les statistiques globales
    global_stats = calculate_global_stats(results)
    
    # 6. Afficher l'analyse d√©taill√©e
    print_detailed_analysis(analysis)
    
    # 7. Afficher le r√©sum√© global
    print("\n\n" + "="*80)
    print("R√âSUM√â GLOBAL")
    print("="*80)
    print(f"\nüìà Sur {global_stats['total_hard_negatives']} hard negatives g√©n√©r√©s:")
    print(f"  ‚Ä¢ < 0.3: {global_stats['global_below_0.3']} ({global_stats['global_below_0.3']/global_stats['total_hard_negatives']*100:.1f}%)")
    print(f"  ‚Ä¢ 0.3-0.6: {global_stats['global_in_range']} ({global_stats['global_percent_in_range']:.1f}%) ‚úì")
    print(f"  ‚Ä¢ > 0.6: {global_stats['global_above_0.6']} ({global_stats['global_above_0.6']/global_stats['total_hard_negatives']*100:.1f}%)")
    print(f"\n  Moyenne globale: {global_stats['global_mean']:.3f}")
    
    # √âvaluation finale
    if global_stats['global_percent_in_range'] >= 70:
        print(f"\nüéØ EXCELLENT: {global_stats['global_percent_in_range']:.0f}% des hard negatives sont dans la cible!")
    elif global_stats['global_percent_in_range'] >= 50:
        print(f"\n‚úÖ BON: {global_stats['global_percent_in_range']:.0f}% des hard negatives sont dans la cible")
    else:
        print(f"\n‚ö†Ô∏è √Ä AM√âLIORER: Seulement {global_stats['global_percent_in_range']:.0f}% dans la cible")
    
    # 8. Sauvegarder le rapport
    save_analysis_report(analysis, global_stats)
    
    print("\n" + "="*80)
    print("Analyse termin√©e!")

if __name__ == "__main__":
    main()