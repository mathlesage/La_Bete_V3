"""
G√©n√©rateur de Hard Negatives avec OpenRouter
"""
import os
import yaml
import json
import random
from typing import List, Dict, Optional
from openai import OpenAI

# Liste des mod√®les disponibles par provider
MODELS = {
    "openai": [
        "openai/gpt-4.1-nano",
    ],
    "google-vertex": [
        "google/gemini-2.5-flash-lite",
    ]
}
def load_prompts():
    """Charge les prompts depuis le fichier YAML"""
    try:
        with open('hard_negatives_prompts.yaml', 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)['prompts']
    except:
        print("Erreur chargement prompts, utilisation prompts par d√©faut")
        return {
            'query_based': [{
                'name': 'default',
                'prompt': 'G√©n√®re une variation de: {query}\nVariation:'
            }],
            'positive_based': [{
                'name': 'default',
                'prompt': 'Modifie: {positive}\nPour la query: {query}\nModification:'
            }]
        }

def apply_aggressive_modification(text: str, original: str) -> str:
    """
    Applique des modifications agressives si le texte est trop similaire
    """
    if not text:
        return None
    
    # Liste de transformations radicales par domaine
    transformations = {
        "python": ["jardinage", "cuisine", "astronomie", "danse"],
        "react": ["chimie", "oc√©an", "histoire", "musique"],
        "installer": ["d√©truire", "manger", "observer", "dessiner"],
        "javascript": ["biologie", "g√©ologie", "po√©sie", "sport"],
        "g√¢teau": ["moteur", "√©quation", "plan√®te", "symphonie"],
        "faire": ["d√©faire", "√©tudier", "r√™ver", "oublier"]
    }
    
    modified = text.lower()
    original_lower = original.lower()
    
    # Remplacer les mots trop similaires
    for key, replacements in transformations.items():
        if key in original_lower and key in modified:
            replacement = random.choice(replacements)
            modified = modified.replace(key, replacement)
    
    # Si toujours trop de mots en commun, g√©n√©rer quelque chose de radical
    original_words = set(original_lower.split())
    modified_words = set(modified.split())
    common_words = original_words & modified_words
    
    # Enlever les mots communs triviaux
    trivial = {"le", "la", "un", "une", "de", "du", "des", "et", "ou", "√†", "?", "comment", "qu'est-ce", "que"}
    common_words = common_words - trivial
    
    if len(common_words) > 2:
        # Trop similaire, cr√©er quelque chose de compl√®tement diff√©rent
        templates = [
            "Les oiseaux migrent vers le sud en hiver.",
            "La th√©orie quantique explique les particules subatomiques.",
            "Les champignons poussent dans les for√™ts humides.",
            "Le jazz est n√© √† la Nouvelle-Orl√©ans.",
            "Les glaciers fondent √† cause du r√©chauffement.",
            "La photosynth√®se transforme la lumi√®re en √©nergie.",
            "Les volcans entrent en √©ruption de fa√ßon impr√©visible.",
            "L'architecture gothique date du Moyen √Çge."
        ]
        return random.choice(templates)
    
    return modified.capitalize()

def generate_hard_negative(prompt: str, model: str = None, provider: str = None, original_text: str = "") -> str:
    """
    G√©n√®re un hard negative en utilisant OpenRouter
    
    Args:
        prompt: Le prompt complet √† envoyer
        model: Le mod√®le √† utiliser (si None, s√©lection al√©atoire)
        provider: Le provider √† utiliser (si sp√©cifi√©, force ce provider)
        original_text: Le texte original pour v√©rification de similarit√©
    
    Returns:
        Le texte g√©n√©r√© ou None si erreur
    """
    # S√©lection du mod√®le
    if model is None:
        if provider and provider in MODELS:
            model = random.choice(MODELS[provider])
        else:
            all_models = [m for models in MODELS.values() for m in models]
            model = random.choice(all_models)
    
    # Configuration pour forcer le provider si sp√©cifi√©
    extra_body = {}
    if provider:
        extra_body["provider"] = {"order": [provider], "allow_fallbacks": False}
    
    # System prompt plus agressif
    system_prompt = """Tu dois cr√©er des phrases TR√àS DIFF√âRENTES de l'original.
    R√®gles STRICTES:
    1. Change COMPL√àTEMENT de domaine (tech‚Üínature, cuisine‚Üím√©canique, etc.)
    2. Maximum 2 mots en commun avec l'original (hors mots comme le/la/un/de)
    3. Ne JAMAIS r√©pondre √† la question originale
    4. Le sens doit √™tre TOTALEMENT diff√©rent
    R√©ponds avec UNE SEULE phrase courte."""
    
    try:
        client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY")
        )
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.9,  # Plus de cr√©ativit√©
            max_tokens=150,
            extra_body=extra_body
        )
        
        result = response.choices[0].message.content.strip()
        
        # Appliquer des modifications agressives si n√©cessaire
        if original_text:
            result = apply_aggressive_modification(result, original_text)
        
        return result
    
    except Exception as e:
        print(f"\n‚ùå Erreur d√©taill√©e: {str(e)}")
        print(f"   Model: {model}")
        print(f"   Provider: {provider}")
        return None

def process_sample(query: str, positive: str, provider: str = None) -> Dict:
    """
    Traite un √©chantillon pour g√©n√©rer ses hard negatives
    
    Args:
        query: La query originale
        positive: La r√©ponse positive
        provider: Le provider √† utiliser (optionnel)
    
    Returns:
        Dict avec query, positive, et les hard negatives g√©n√©r√©s
    """
    prompts = load_prompts()
    
    # S√©lectionner un prompt al√©atoire pour query-based
    query_prompt_config = random.choice(prompts['query_based'])
    query_prompt = query_prompt_config['prompt'].format(query=query)
    
    # S√©lectionner un prompt al√©atoire pour positive-based
    positive_prompt_config = random.choice(prompts['positive_based'])
    positive_prompt = positive_prompt_config['prompt'].format(query=query, positive=positive)
    
    # G√©n√©rer les hard negatives
    hard_neg_from_query = generate_hard_negative(query_prompt, provider=provider)
    hard_neg_from_positive = generate_hard_negative(positive_prompt, provider=provider)
    
    # Messages d'erreur plus informatifs
    if hard_neg_from_query is None:
        print(f"  ‚ö†Ô∏è √âchec g√©n√©ration hard_neg_from_query")
        hard_neg_from_query = f"[Erreur] Variation de: {query[:50]}..."
    
    if hard_neg_from_positive is None:
        print(f"  ‚ö†Ô∏è √âchec g√©n√©ration hard_neg_from_positive")
        hard_neg_from_positive = f"[Erreur] Modification de: {positive[:50]}..."
    
    return {
        'query': query,
        'positive': positive,
        'hard_negative_from_query': hard_neg_from_query,
        'hard_negative_from_positive': hard_neg_from_positive,
        'prompt_used_query': query_prompt_config['name'],
        'prompt_used_positive': positive_prompt_config['name']
    }

def main():
    """Fonction principale"""
    
    # V√©rifier la cl√© API
    if not os.getenv("OPENROUTER_API_KEY"):
        print("‚ùå OPENROUTER_API_KEY non d√©finie")
        print("export OPENROUTER_API_KEY='votre_cl√©'")
        return
    
    # Dataset √† utiliser
    # V√©rifier d'abord si dataset_100.json existe
    try:
        with open('dataset_100.json', 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        print(f"‚úì Dataset charg√© depuis dataset_100.json: {len(dataset)} √©chantillons")
    except FileNotFoundError:
        print("dataset_100.json non trouv√©, utilisation du dataset d'exemple")
        dataset = [
            {
                "query": "Comment installer Python ?",
                "positive": "T√©l√©chargez Python depuis python.org et lancez l'installateur."
            },
            {
                "query": "Qu'est-ce que React ?",
                "positive": "React est une biblioth√®que JavaScript pour cr√©er des interfaces utilisateur."
            },
            {
                "query": "Comment faire un g√¢teau ?",
                "positive": "M√©langez farine, ≈ìufs, sucre et beurre, puis enfournez 30 minutes √† 180¬∞C."
            },
            {
                "query": "Quelle est la capitale de la France ?",
                "positive": "La capitale de la France est Paris, situ√©e sur la Seine."
            },
            {
                "query": "Comment d√©boguer du code JavaScript ?",
                "positive": "Utilisez console.log, les breakpoints et les outils de d√©veloppement du navigateur."
            },
            {
                "query": "Qu'est-ce que Docker ?",
                "positive": "Docker est une plateforme de conteneurisation pour empaqueter des applications."
            },
            {
                "query": "Comment apprendre le machine learning ?",
                "positive": "Commencez par les math√©matiques, puis Python, et suivez des cours en ligne."
            },
            {
                "query": "Pourquoi le ciel est bleu ?",
                "positive": "La lumi√®re bleue est diffus√©e par les mol√©cules d'air dans l'atmosph√®re."
            },
            {
                "query": "Comment cr√©er une API REST ?",
                "positive": "D√©finissez les endpoints, utilisez HTTP verbs et retournez du JSON."
            },
            {
                "query": "Qu'est-ce que Git ?",
                "positive": "Git est un syst√®me de contr√¥le de version distribu√© pour le code source."
            }
        ]
    
    # Demander le provider
    print("\nProviders disponibles:")
    providers_list = list(MODELS.keys())
    for i, p in enumerate(providers_list, 1):
        models_count = len(MODELS[p])
        print(f"  {i}. {p} ({models_count} mod√®le{'s' if models_count > 1 else ''})")
    print(f"  {len(providers_list)+1}. Tous (al√©atoire)")
    
    choice = input("\nChoisir (num√©ro): ").strip()
    
    provider = None
    if choice.isdigit():
        idx = int(choice) - 1
        if 0 <= idx < len(providers_list):
            provider = providers_list[idx]
            print(f"‚úì Provider: {provider}")
        else:
            print("‚úì Tous les providers")
    
    # Traiter le dataset
    print("\nG√©n√©ration des hard negatives...")
    results = []
    
    for sample in dataset:
        print(f"\nTraitement: {sample['query'][:50]}...")
        result = process_sample(sample['query'], sample['positive'], provider)
        results.append(result)
        
        # Afficher le r√©sultat
        print(f"  ‚úì Hard neg (query): {result['hard_negative_from_query'][:60]}...")
        print(f"  ‚úì Hard neg (positive): {result['hard_negative_from_positive'][:60]}...")
    
    # Sauvegarder les r√©sultats
    with open('hard_negatives_output.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ {len(results)} √©chantillons g√©n√©r√©s")
    print("üìÅ Sauvegard√© dans: hard_negatives_output.json")

if __name__ == "__main__":
    main()